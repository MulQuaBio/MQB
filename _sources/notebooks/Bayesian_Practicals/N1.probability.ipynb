{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical session 1. Mendelian peas\n",
    "\n",
    "In this session we will explore how to deal with probability functions and Bayes theorem computationally. The first step in any python script is loading the libraries that we will use. \n",
    "Feel free to use the internet to find information on these libraries. It is specially useful to understand how to navigate their online documentation. For instance scipy (https://docs.scipy.org/). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # numpy is the standard numeric libray\n",
    "import scipy.stats as ss # scipy is the scientific library, the stats module contains different functions\n",
    "import matplotlib.pyplot as plt # matplotlib is the standard plotting library\n",
    "import seaborn as sns # library for statistical plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Part 1: Warming up: Conditional probabilities\n",
    "\n",
    "We will start with some analytical derivations, you will not need pytong for this part.\n",
    "In the paradigmatic genetics example (i.e., Mendel and the peas) studying the prevalence of a dominant and recesive genes, we know the following:\n",
    "- There are two alleles of the gene: Y is dominant and y is recessive. The former corresponds to yellow peas and the latter to green peas.\n",
    "- We assume that peas are diploid. Therefore, their genotype can be homozygote (YY or yy) or heterozygote (yY, Yy). We assume equal probabilities for alleles, so: P(homozygote) = P(heterozygote) = 1/2.\n",
    "\n",
    "**Question 1.1** What is the probability of observing a yellow pea $P(\\mathrm{yellow})$?\n",
    "\n",
    "**Question 1.2** What is the probability that a yellow pea is heterozygote $P(\\mathrm{heteroz.}|\\mathrm{yellow})$?\n",
    "\n",
    "**Question 1.3** What is the probability that a pea is yellow and heterozygote $P(\\mathrm{heteroz.}\\,,\\mathrm{yellow})$?\n",
    "\n",
    "**Question 1.4** Use the Bayes' theorem to calculate the probability that a pea is yellow knowing that it is heterozygote $P(\\mathrm{yellow}|\\mathrm{heteroz.})$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Part 2: Manipulating probabilities with Python\n",
    "\n",
    "A neighbour of Mendel sneaks in Mendel's garden at night and picks 10 peas at random. **What is the probability that he gets exactly 5 yellow peas?**\n",
    "\n",
    "This question can be answered in 3 different ways. Let's try to implement them one by one: \n",
    "\n",
    "#### Method 1 - Brute Force\n",
    "Sometimes we do not know the mathematical closed form of a distribution, but we know how to sample it. In these cases, we can build an empirical distribution function. For instance, in this case we can simulate many times the experiment: generate computationally 10 peas that can be green or yellow at random with the corresponding probability and counting the number of yellow peas. Here you have a function that generates 1 experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All these three functions do the same and are interchangable,\n",
    "# they reproduce the experiment of selecting 10 peas at random\n",
    "# have a look at them and make sure you understand the python syntax used in each of them\n",
    "\n",
    "def peas_experiment():\n",
    "    results = [] # empty list that will be filled with each draw of a pea\n",
    "    # for each draw we want to add a 1 if the pea is yellow\n",
    "    # or a 0 if the pea is green\n",
    "    for i in range(10): # for each pea 1,2,3,4...,10\n",
    "        if np.random.rand()<3/4: # np.random.rand() generates a uniform random number in the range [0,1) \n",
    "            results.append(1)\n",
    "        else:\n",
    "            results.append(0)\n",
    "    return results\n",
    "    \n",
    "def peas_experiment_pythonic():\n",
    "    # the function above is non-pythonic, we try to avoid loops in python.\n",
    "    # A cleaner way of writing the same function is\n",
    "    return [int(x<3/4) for x in np.random.rand(10)] \n",
    "\n",
    "\n",
    "def peas_experiment_scipy(): \n",
    "    # another alternative is using the scipy.stats functions that contain implemented probability distributions\n",
    "    # in our case we want to repeat a Bernoulli experiment 10 times.\n",
    "    # A Bernoulli experiment is throwing a coin that is rigged to one side with a certain probability\n",
    "    return ss.bernoulli.rvs(p = 3/4,size = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1** Run one of the function defined in the previous cell 1000 times and store for each of them the number of yellow peas observed. Which is the fraction of times you observe 5 yellow peas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test of the functions above. As an example we are calling peas_experiment() \n",
    "\n",
    "print(\"Here are three independent realizations of the experiment:\")\n",
    "for N in range(3):\n",
    "    print(peas_experiment_pythonic())\n",
    "\n",
    "#Here you should write the code that returns the answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2 (optional)** Find a credibility/confidence interval to the answer to Question 2.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3 (optional)** The three functions `peas_experiment()`, `peas_experiment_pythonic()`, and `peas_experiment_scipy()` do the same, but they have different efficiency. Calculate how much time it takes for them to run 1000 experiments, you can use the library `time`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2 - Scipy binomial distribution\n",
    "The binomial pmf (probability mass function, or discrete probability distribution) describes the probability of observing $n$ events when sampling $N$ times if each event has a probability $p$ of occurring within each sample. This is exactly the probability distribution that we need.\n",
    "\n",
    "**Question 2.4** Look for the scipy implementation of the binomial distribution and solve the question. Note that scipy probability distributions are python classes with different methods (functions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here you should write the code that returns the answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 3 - Analytical binomial distribution\n",
    "**Question 2.5** The binomial pmf has a simple analytical closed form. Find the formula (no python required) to solve the same question 2.4. Compare the results obtained in Methods 1,2, and 3. Are they the same? why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6** Instead of the original question \"What is the probability that he gets exactly 5 yellow peas?\", we could ask a more general question: **What is the probability that he gets exactly n yellow peas?**. Generate a histogram of the probability of getting $n$ yellow peas. As an example here is a piece of code to plot a histograms with hypothetical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # One possible way of summarizing data in python is using dataframes with the library pandas\n",
    "data1 = pd.DataFrame({\n",
    "    'Bins': [1,2,3,4], # the names of the fields ('Bins', 'Counts', 'Source') are arbitrary\n",
    "    'Counts': [50,50,0,100],\n",
    "    'Source': 'experiment1'\n",
    "})\n",
    " \n",
    "display(data1)\n",
    "sns.barplot(data1, x = 'Bins', y = 'Counts', hue = 'Source')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.7** What is the probability that he gets **at least** 5 yellow peas? You can solve this using the cumulative density function CDF. Check it at the documentation of the binomial at scipy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 : Introducing priors: Bayesian inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neighbour picked a certain number $N$ of peas. They remember that 5 of them were yellow, but they do not remember the exact total number $N$ of peas they picked. The only think that they remember is that they picked between $N=5$ and $N=10$ peas. What is the most probable value of $N$?\n",
    "\n",
    "Note that this is a Bayesian problem! We have a parameter $N$ that we want to infer. We have a prior knowledge of $N$ (a number between 5 and 10). We also know from Part 2 the probability (likelihood) of obtaining $n=5$ peas given different possible values of $N$.\n",
    "\n",
    "**Question 3.1** Use Bayes' theorem to frame the problem analytically\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1** The next code can be used to solve the problem numerically by evaluating the posterior distribution at different values of $N$.  What is the most probable value of $N$?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rangeN = range(5,11) # possible values of N \n",
    "likelihoodN = [ss.binom.pmf(5,N,3/4) for N in rangeN]\n",
    "idx = np.argmax(likelihoodN)\n",
    "\n",
    "print(\"N    Likelihood\")\n",
    "for i in range(6):\n",
    "    print(rangeN[i], likelihoodN[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2** How would the result of Question 1.5 change if you know the information that the initial random number of peas $N$ was selected from a Poisson distribution of mean $\\langle N \\rangle = 10$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3** In this case we could solve the problem without requiring any sophisticated sampling. Nevertheless let's try to solve the same problem using pyMC, a Python library for numerical Bayesian inference. The code below solves the problem for question 1.6 where the prior distribution was a uniform distribution between N = 5 and N = 10. Two addicional Jupyter cells are included plotting the MCMC traces, and a histogram of the results. Run the code and compare the results with your results of answer 1.6 by plotting both posterior distributions together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm # library for Bayesian MCMC inference\n",
    "\n",
    "with pm.Model() as Pea_Model:\n",
    "    N = pm.DiscreteUniform(\"N\",5,10) # Our prior distribution for N is a Poisson\n",
    "    yellow_Likelihood = pm.Binomial(\"Yellow\", n=N, p = 3/4, observed = 5) # Likelihood of observing 5 yellow peas is\n",
    "    #a binomial of picking N peas each one with a probability p=3/4 of being yellow\n",
    "    mcmc_sample = pm.sample(4000, chains = 2, return_inferencedata = True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az # arviz is a library useful to plot an analyze MCMC chains, \n",
    "az.plot_trace(mcmc_sample, compact = False) # plot of posterior and traces\n",
    "az.summary(mcmc_sample) # summary of MCMC statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arvix is very useful, but sometimes you want to extract the traces data to extract particular information\n",
    "# The object mcmc_sample is an xarray with many information, we can extract just the posterior values of N as:\n",
    "posteriorN = mcmc_sample.posterior.N # extract the values of N for the posterior distribution\n",
    "posteriorN_all = posteriorN.values.ravel() # flatten the array to gather all the chains in a single array\n",
    "\n",
    "# You can use posteriorN_all to compare the results with your values from \n",
    "# Since the data is discrete You can count how many occurrences for each value of N in the posterior\n",
    "values_N, counts_N = np.unique(posteriorN_all, return_counts=True)\n",
    "data = pd.DataFrame({'N': values_N, 'counts': counts_N})\n",
    "sns.barplot(data, x = 'N', y ='counts', color = 'violet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4** Analyze the MCMC statistics given by az.summary(). Has the MCMC converged?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5 (Optional)** ``az.summary()`` was used in Q3.4 to analyze the convergence of the MCMC. One of the statistics used is ``ess_tail``. Used to calculate the effective size in the tail. Can you find in the source code of ``arviz`` library how the tail is calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6** Copy the code in Q3.4 and modify it to answer question Q3.3 (Poisson prior) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can write your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

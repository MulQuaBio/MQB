
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Practical session 1. Mendelian peas &#8212; MulQuaBio</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=01a0bdc2" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/Bayesian_Practicals/N1.probability';</script>
    <script src="https://cdn.jsdelivr.net/npm/@iframe-resizer/child@latest"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="MulQuaBio - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="MulQuaBio - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Welcome to The Multilingual Quantitative Biologist!
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Computing</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Unix.html">UNIX and Linux</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ShellScripting.html">Shell scripting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Git.html">Version control with Git</a></li>
<li class="toctree-l1"><a class="reference internal" href="../LaTeX.html">Scientific documents with <span class="math notranslate nohighlight">\(\LaTeX\)</span></a></li>
<li class="toctree-l1"><a class="reference internal" href="../Python.html">Biological Computing in Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../R.html">Biological Computing in R</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ecological &amp; Evolutionary Modelling</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../MetabolicBasis.html">The Metabolic Basis of Ecology and Evolutionary dynamics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Populations.html">Single Populations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Interactions.html">Species Interactions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../references.html">References</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Basic Data Analyses and Statistics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../intro-Stats.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Data_R.html">Data Management and Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ExpDesign.html">Experimental design and Data exploration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../t_F_tests.html">Basic hypothesis testing: <span class="math notranslate nohighlight">\(t\)</span> and <span class="math notranslate nohighlight">\(F\)</span> tests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Regress.html">Linear Models: Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ANOVA.html">Linear Models: Analysis of variance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../MulExpl.html">Linear Models: Multiple explanatory variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../MulExplInter.html">Linear Models: Multiple variables with interactions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ModelSimp.html">Model simplification</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced Data Analyses and Statistics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../GLMs.html">Generalised Linear Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../NLLS.html">Model Fitting using Non-linear Least-squares</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendices</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Appendix-JupyIntro.html">Introduction to Jupyter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Appendix-Data-Python.html">Data analyses  with Python &amp; Jupyter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Appendix-Maths.html">Mathematical models in Jupyter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Appendix-MathsForBiologists/MathsForBiologists.html">Maths for Biologists</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Appendix-Databases.html">Databases <span class="tocSkip"></span></a></li>
<li class="toctree-l1"><a class="reference internal" href="../Appendix-NLLS-Python.html">Model fitting in Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Appendix-MiniProj.html">The Computing Miniproject</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Appendix-Assessment.html">TMQB Coursework Assessment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Appendix-HighPerformanceComputing.html">Introduction to High-Performance Computing (HPC)</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/MulQuaBio/MQB" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/MulQuaBio/MQB/issues/new?title=Issue%20on%20page%20%2Fnotebooks/Bayesian_Practicals/N1.probability.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/notebooks/Bayesian_Practicals/N1.probability.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Practical session 1. Mendelian peas</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-1-warming-up-conditional-probabilities">Part 1: Warming up: Conditional probabilities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-2-manipulating-probabilities-with-python">Part 2: Manipulating probabilities with Python</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#method-1-brute-force">Method 1 - Brute Force</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#method-2-scipy-binomial-distribution">Method 2 - Scipy binomial distribution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#method-3-analytical-binomial-distribution">Method 3 - Analytical binomial distribution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-3-introducing-priors-bayesian-inference">Part 3 : Introducing priors: Bayesian inference</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="practical-session-1-mendelian-peas">
<h1>Practical session 1. Mendelian peas<a class="headerlink" href="#practical-session-1-mendelian-peas" title="Link to this heading">#</a></h1>
<p>In this session we will explore how to deal with probability functions and Bayes theorem computationally. The first step in any python script is loading the libraries that we will use.
Feel free to use the internet to find information on these libraries. It is specially useful to understand how to navigate their online documentation. For instance scipy (<a class="reference external" href="https://docs.scipy.org/">https://docs.scipy.org/</a>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span> <span class="c1"># numpy is the standard numeric libray</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ss</span> <span class="c1"># scipy is the scientific library, the stats module contains different functions</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span> <span class="c1"># matplotlib is the standard plotting library</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span> <span class="c1"># library for statistical plotting</span>
</pre></div>
</div>
</div>
</div>
<section id="part-1-warming-up-conditional-probabilities">
<h2>Part 1: Warming up: Conditional probabilities<a class="headerlink" href="#part-1-warming-up-conditional-probabilities" title="Link to this heading">#</a></h2>
<p>We will start with some analytical derivations, you will not need pytong for this part.
In the paradigmatic genetics example (i.e., Mendel and the peas) studying the prevalence of a dominant and recesive genes, we know the following:</p>
<ul class="simple">
<li><p>There are two alleles of the gene: Y is dominant and y is recessive. The former corresponds to yellow peas and the latter to green peas.</p></li>
<li><p>We assume that peas are diploid. Therefore, their genotype can be homozygote (YY or yy) or heterozygote (yY, Yy). We assume equal probabilities for alleles, so: P(homozygote) = P(heterozygote) = 1/2.</p></li>
</ul>
<p><strong>Question 1.1</strong> What is the probability of observing a yellow pea <span class="math notranslate nohighlight">\(P(\mathrm{yellow})\)</span>?</p>
<p><strong>Question 1.2</strong> What is the probability that a yellow pea is heterozygote <span class="math notranslate nohighlight">\(P(\mathrm{heteroz.}|\mathrm{yellow})\)</span>?</p>
<p><strong>Question 1.3</strong> What is the probability that a pea is yellow and heterozygote <span class="math notranslate nohighlight">\(P(\mathrm{heteroz.}\,,\mathrm{yellow})\)</span>?</p>
<p><strong>Question 1.4</strong> Use the Bayes’ theorem to calculate the probability that a pea is yellow knowing that it is heterozygote <span class="math notranslate nohighlight">\(P(\mathrm{yellow}|\mathrm{heteroz.})\)</span>?</p>
</section>
<section id="part-2-manipulating-probabilities-with-python">
<h2>Part 2: Manipulating probabilities with Python<a class="headerlink" href="#part-2-manipulating-probabilities-with-python" title="Link to this heading">#</a></h2>
<p>A neighbour of Mendel sneaks in Mendel’s garden at night and picks 10 peas at random. <strong>What is the probability that he gets exactly 5 yellow peas?</strong></p>
<p>This question can be answered in 3 different ways. Let’s try to implement them one by one:</p>
<section id="method-1-brute-force">
<h3>Method 1 - Brute Force<a class="headerlink" href="#method-1-brute-force" title="Link to this heading">#</a></h3>
<p>Sometimes we do not know the mathematical closed form of a distribution, but we know how to sample it. In these cases, we can build an empirical distribution function. For instance, in this case we can simulate many times the experiment: generate computationally 10 peas that can be green or yellow at random with the corresponding probability and counting the number of yellow peas. Here you have a function that generates 1 experiment:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## All these three functions do the same and are interchangable,</span>
<span class="c1"># they reproduce the experiment of selecting 10 peas at random</span>
<span class="c1"># have a look at them and make sure you understand the python syntax used in each of them</span>

<span class="k">def</span><span class="w"> </span><span class="nf">peas_experiment</span><span class="p">():</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># empty list that will be filled with each draw of a pea</span>
    <span class="c1"># for each draw we want to add a 1 if the pea is yellow</span>
    <span class="c1"># or a 0 if the pea is green</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span> <span class="c1"># for each pea 1,2,3,4...,10</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span><span class="o">&lt;</span><span class="mi">3</span><span class="o">/</span><span class="mi">4</span><span class="p">:</span> <span class="c1"># np.random.rand() generates a uniform random number in the range [0,1) </span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">results</span>
    
<span class="k">def</span><span class="w"> </span><span class="nf">peas_experiment_pythonic</span><span class="p">():</span>
    <span class="c1"># the function above is non-pythonic, we try to avoid loops in python.</span>
    <span class="c1"># A cleaner way of writing the same function is</span>
    <span class="k">return</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="o">&lt;</span><span class="mi">3</span><span class="o">/</span><span class="mi">4</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span> 


<span class="k">def</span><span class="w"> </span><span class="nf">peas_experiment_scipy</span><span class="p">():</span> 
    <span class="c1"># another alternative is using the scipy.stats functions that contain implemented probability distributions</span>
    <span class="c1"># in our case we want to repeat a Bernoulli experiment 10 times.</span>
    <span class="c1"># A Bernoulli experiment is throwing a coin that is rigged to one side with a certain probability</span>
    <span class="k">return</span> <span class="n">ss</span><span class="o">.</span><span class="n">bernoulli</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">p</span> <span class="o">=</span> <span class="mi">3</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span><span class="n">size</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Question 2.1</strong> Run one of the function defined in the previous cell 1000 times and store for each of them the number of yellow peas observed. Which is the fraction of times you observe 5 yellow peas?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Test of the functions above. As an example we are calling peas_experiment() </span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Here are three independent realizations of the experiment:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">N</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">peas_experiment_pythonic</span><span class="p">())</span>

<span class="c1">#Here you should write the code that returns the answer. </span>
</pre></div>
</div>
</div>
</div>
<p><strong>Question 2.2 (optional)</strong> Find a credibility/confidence interval to the answer to Question 2.1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># You can write your code here</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Question 2.3 (optional)</strong> The three functions <code class="docutils literal notranslate"><span class="pre">peas_experiment()</span></code>, <code class="docutils literal notranslate"><span class="pre">peas_experiment_pythonic()</span></code>, and <code class="docutils literal notranslate"><span class="pre">peas_experiment_scipy()</span></code> do the same, but they have different efficiency. Calculate how much time it takes for them to run 1000 experiments, you can use the library <code class="docutils literal notranslate"><span class="pre">time</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># You can write your code here</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="method-2-scipy-binomial-distribution">
<h3>Method 2 - Scipy binomial distribution<a class="headerlink" href="#method-2-scipy-binomial-distribution" title="Link to this heading">#</a></h3>
<p>The binomial pmf (probability mass function, or discrete probability distribution) describes the probability of observing <span class="math notranslate nohighlight">\(n\)</span> events when sampling <span class="math notranslate nohighlight">\(N\)</span> times if each event has a probability <span class="math notranslate nohighlight">\(p\)</span> of occurring within each sample. This is exactly the probability distribution that we need.</p>
<p><strong>Question 2.4</strong> Look for the scipy implementation of the binomial distribution and solve the question. Note that scipy probability distributions are python classes with different methods (functions)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Here you should write the code that returns the answer. </span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="method-3-analytical-binomial-distribution">
<h3>Method 3 - Analytical binomial distribution<a class="headerlink" href="#method-3-analytical-binomial-distribution" title="Link to this heading">#</a></h3>
<p><strong>Question 2.5</strong> The binomial pmf has a simple analytical closed form. Find the formula (no python required) to solve the same question 2.4. Compare the results obtained in Methods 1,2, and 3. Are they the same? why?</p>
<p><strong>Question 2.6</strong> Instead of the original question “What is the probability that he gets exactly 5 yellow peas?”, we could ask a more general question: <strong>What is the probability that he gets exactly n yellow peas?</strong>. Generate a histogram of the probability of getting <span class="math notranslate nohighlight">\(n\)</span> yellow peas. As an example here is a piece of code to plot a histograms with hypothetical data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span> <span class="c1"># One possible way of summarizing data in python is using dataframes with the library pandas</span>
<span class="n">data1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;Bins&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="c1"># the names of the fields (&#39;Bins&#39;, &#39;Counts&#39;, &#39;Source&#39;) are arbitrary</span>
    <span class="s1">&#39;Counts&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">100</span><span class="p">],</span>
    <span class="s1">&#39;Source&#39;</span><span class="p">:</span> <span class="s1">&#39;experiment1&#39;</span>
<span class="p">})</span>
 
<span class="n">display</span><span class="p">(</span><span class="n">data1</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">data1</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="s1">&#39;Bins&#39;</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s1">&#39;Counts&#39;</span><span class="p">,</span> <span class="n">hue</span> <span class="o">=</span> <span class="s1">&#39;Source&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Question 2.7</strong> What is the probability that he gets <strong>at least</strong> 5 yellow peas? You can solve this using the cumulative density function CDF. Check it at the documentation of the binomial at scipy.</p>
</section>
</section>
<section id="part-3-introducing-priors-bayesian-inference">
<h2>Part 3 : Introducing priors: Bayesian inference<a class="headerlink" href="#part-3-introducing-priors-bayesian-inference" title="Link to this heading">#</a></h2>
<p>The neighbour picked a certain number <span class="math notranslate nohighlight">\(N\)</span> of peas. They remember that 5 of them were yellow, but they do not remember the exact total number <span class="math notranslate nohighlight">\(N\)</span> of peas they picked. The only think that they remember is that they picked between <span class="math notranslate nohighlight">\(N=5\)</span> and <span class="math notranslate nohighlight">\(N=10\)</span> peas. What is the most probable value of <span class="math notranslate nohighlight">\(N\)</span>?</p>
<p>Note that this is a Bayesian problem! We have a parameter <span class="math notranslate nohighlight">\(N\)</span> that we want to infer. We have a prior knowledge of <span class="math notranslate nohighlight">\(N\)</span> (a number between 5 and 10). We also know from Part 2 the probability (likelihood) of obtaining <span class="math notranslate nohighlight">\(n=5\)</span> peas given different possible values of <span class="math notranslate nohighlight">\(N\)</span>.</p>
<p><strong>Question 3.1</strong> Use Bayes’ theorem to frame the problem analytically</p>
<p><strong>Question 3.1</strong> The next code can be used to solve the problem numerically by evaluating the posterior distribution at different values of <span class="math notranslate nohighlight">\(N\)</span>.  What is the most probable value of <span class="math notranslate nohighlight">\(N\)</span>?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rangeN</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">11</span><span class="p">)</span> <span class="c1"># possible values of N </span>
<span class="n">likelihoodN</span> <span class="o">=</span> <span class="p">[</span><span class="n">ss</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="mi">3</span><span class="o">/</span><span class="mi">4</span><span class="p">)</span> <span class="k">for</span> <span class="n">N</span> <span class="ow">in</span> <span class="n">rangeN</span><span class="p">]</span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">likelihoodN</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;N    Likelihood&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">rangeN</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">likelihoodN</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Question 3.2</strong> How would the result of Question 1.5 change if you know the information that the initial random number of peas <span class="math notranslate nohighlight">\(N\)</span> was selected from a Poisson distribution of mean <span class="math notranslate nohighlight">\(\langle N \rangle = 10\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Write your code here</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Question 3.3</strong> In this case we could solve the problem without requiring any sophisticated sampling. Nevertheless let’s try to solve the same problem using pyMC, a Python library for numerical Bayesian inference. The code below solves the problem for question 1.6 where the prior distribution was a uniform distribution between N = 5 and N = 10. Two addicional Jupyter cells are included plotting the MCMC traces, and a histogram of the results. Run the code and compare the results with your results of answer 1.6 by plotting both posterior distributions together</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pymc</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pm</span> <span class="c1"># library for Bayesian MCMC inference</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">Pea_Model</span><span class="p">:</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">DiscreteUniform</span><span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span> <span class="c1"># Our prior distribution for N is a Poisson</span>
    <span class="n">yellow_Likelihood</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Binomial</span><span class="p">(</span><span class="s2">&quot;Yellow&quot;</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">3</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span> <span class="n">observed</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span> <span class="c1"># Likelihood of observing 5 yellow peas is</span>
    <span class="c1">#a binomial of picking N peas each one with a probability p=3/4 of being yellow</span>
    <span class="n">mcmc_sample</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">4000</span><span class="p">,</span> <span class="n">chains</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">return_inferencedata</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">arviz</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">az</span> <span class="c1"># arviz is a library useful to plot an analyze MCMC chains, </span>
<span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">mcmc_sample</span><span class="p">,</span> <span class="n">compact</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="c1"># plot of posterior and traces</span>
<span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">mcmc_sample</span><span class="p">)</span> <span class="c1"># summary of MCMC statistics</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># arvix is very useful, but sometimes you want to extract the traces data to extract particular information</span>
<span class="c1"># The object mcmc_sample is an xarray with many information, we can extract just the posterior values of N as:</span>
<span class="n">posteriorN</span> <span class="o">=</span> <span class="n">mcmc_sample</span><span class="o">.</span><span class="n">posterior</span><span class="o">.</span><span class="n">N</span> <span class="c1"># extract the values of N for the posterior distribution</span>
<span class="n">posteriorN_all</span> <span class="o">=</span> <span class="n">posteriorN</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span> <span class="c1"># flatten the array to gather all the chains in a single array</span>

<span class="c1"># You can use posteriorN_all to compare the results with your values from </span>
<span class="c1"># Since the data is discrete You can count how many occurrences for each value of N in the posterior</span>
<span class="n">values_N</span><span class="p">,</span> <span class="n">counts_N</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">posteriorN_all</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;N&#39;</span><span class="p">:</span> <span class="n">values_N</span><span class="p">,</span> <span class="s1">&#39;counts&#39;</span><span class="p">:</span> <span class="n">counts_N</span><span class="p">})</span>
<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span><span class="s1">&#39;counts&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;violet&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Question 3.4</strong> Analyze the MCMC statistics given by az.summary(). Has the MCMC converged?</p>
<p><strong>Question 3.5 (Optional)</strong> <code class="docutils literal notranslate"><span class="pre">az.summary()</span></code> was used in Q3.4 to analyze the convergence of the MCMC. One of the statistics used is <code class="docutils literal notranslate"><span class="pre">ess_tail</span></code>. Used to calculate the effective size in the tail. Can you find in the source code of <code class="docutils literal notranslate"><span class="pre">arviz</span></code> library how the tail is calculated?</p>
<p><strong>Question 3.6</strong> Copy the code in Q3.4 and modify it to answer question Q3.3 (Poisson prior)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># You can write your code here</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks/Bayesian_Practicals"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-1-warming-up-conditional-probabilities">Part 1: Warming up: Conditional probabilities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-2-manipulating-probabilities-with-python">Part 2: Manipulating probabilities with Python</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#method-1-brute-force">Method 1 - Brute Force</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#method-2-scipy-binomial-distribution">Method 2 - Scipy binomial distribution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#method-3-analytical-binomial-distribution">Method 3 - Analytical binomial distribution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-3-introducing-priors-bayesian-inference">Part 3 : Introducing priors: Bayesian inference</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By MulQuaBio collective!
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>